{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Not proper testing you run into execution errors in code due to software issues you could also be dictating business decisions affect products based on faulty conclusions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bad encoding\n",
    "* Inappropriate features\n",
    "* Unexpected features\n",
    "\n",
    "Therefore proper testing to be confident about results and to avoid surprises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test driven development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing tests before developing code to implement tasks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that covers a small unit of code, usually a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and data science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* write unit tests\n",
    "* Tools to improve unit tests\n",
    "* Test specifically for data science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unit test demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you wanted to test a function that finds the nearest perfect square less than or equal to cetain number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nearest import nearest_square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_square(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_square(-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_square(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_square(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's poor way to test because this isn't repeatable and requires you to type these manually and doesn't tell whether it's returning correct answer. It is inefficient and unreliable way of testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you may consider putting test code inside file to make it repeatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest square <=5: 4\n",
      "Nearest square <=-12: 0\n",
      "Nearest square <=13: 9\n",
      "Nearest square <=23: 16\n"
     ]
    }
   ],
   "source": [
    "# %load bad_test1.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "from nearest import nearest_square\n",
    "\n",
    "\n",
    "print(\"Nearest square <=5:\",nearest_square(5))\n",
    "print(\"Nearest square <=-12:\",nearest_square(-12))\n",
    "print(\"Nearest square <=13:\",nearest_square(13))\n",
    "print(\"Nearest square <=23:\",nearest_square(23))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Still have to check manually whether results are correct or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we print correct expected result with each answer,now we do have a clear way to check out results. However still have to manually compare what they returned and correct answer yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest square <=5 returned:4,actual answer is 4\n",
      "Nearest square <=-12 returned:0,actual answer is 0\n",
      "Nearest square <=9 returned:9,actual answer is 9\n",
      "Nearest square <=23 returned:16,actual answer is 16\n"
     ]
    }
   ],
   "source": [
    "# %load bad_test2.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "\n",
    "from nearest import nearest_square\n",
    "\n",
    "\n",
    "print('Nearest square <=5 returned:{},actual answer is 4'.format(nearest_square(5)))\n",
    "print('Nearest square <=-12 returned:{},actual answer is 0'.format(nearest_square(-12)))\n",
    "print('Nearest square <=9 returned:{},actual answer is 9'.format(nearest_square(9)))\n",
    "print('Nearest square <=23 returned:{},actual answer is 16'.format(nearest_square(23)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is not ideal when we are running large amount of tests**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can use assert to ensure that each result is identical to the correct answer.This is much better since it checks  out results automatically.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest square <=5 returned:<function nearest_square at 0x0000012B24045EA0>,actual answer is 4\n",
      "Nearest square <=-12 returned:0,actual answer is 0\n",
      "Nearest square <=9 returned:9,actual answer is 9\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-adf341b9af55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mnearest_9\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnearest_square\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Nearest square <=9 returned:{},actual answer is 9'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnearest_9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnearest_9\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mnearest_23\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnearest_square\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %load bad_test3.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "\n",
    "\n",
    "from nearest import nearest_square\n",
    "\n",
    "nearest_5=nearest_square(5)\n",
    "print('Nearest square <=5 returned:{},actual answer is 4'.format(nearest_square))\n",
    "assert(nearest_5==4)\n",
    "      \n",
    "nearest_n12=nearest_square(-12)\n",
    "print('Nearest square <=-12 returned:{},actual answer is 0'.format(nearest_n12))\n",
    "assert(nearest_n12==0)\n",
    "      \n",
    "nearest_9=nearest_square(9)\n",
    "print('Nearest square <=9 returned:{},actual answer is 9'.format(nearest_9))\n",
    "assert(nearest_9==0)\n",
    "      \n",
    "nearest_23=nearest_square(23)\n",
    "print('Nearest square <=23 returned:{},actual answer is 16'.format(nearest_23))\n",
    "assert(nearest_23==16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This result is messy and it stops the program.Ideally running  a test should run all the unit tests and let you know which ones failed and which ones succeeded. This can't happen if it stops with every failure.Any tests that happened after  failed one in our case nearest_9 ,we can't see the result of.In addition,message where failure is messier than it needs to be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Tests\n",
    "`We want to test our functions in a way that is repeatable and automated. Ideally, we'd run a test program that runs all our unit tests and cleanly lets us know which ones failed and which ones succeeded.` Fortunately, there are great tools available in Python that we can use to create effective unit tests!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test Advantages and Disadvantages\n",
    "`The advantage of unit tests is that they are isolated from the rest of your program, and thus, no dependencies are involved. They don't require access to databases, APIs, or other external sources of information`. However, passing unit tests isn’t always enough to prove that our program is working successfully. `To show that all the parts of our program work with each other properly, communicating and transferring data between them correctly, we use` **'integration tests'**. In this lesson, we'll focus on unit tests; however, when you start building larger programs, you will want to use integration tests as well.\n",
    "\n",
    "You can read about integration testing and how integration tests relate to unit tests [here](https://www.fullstackpython.com/integration-testing.html). That article contains other very useful links as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit testing tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytest is great tool that lets you start testing quickly without any boiler plate code.\n",
    "\n",
    "### Install Pytest\n",
    "`pip install -U pytest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Then enter pytest file in directory of test file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Driven Development and Data Science\n",
    "**TEST DRIVEN DEVELOPMENT:** writing tests before you write the code that’s being tested. Your test would fail at first, and you’ll know you’ve finished implementing a task when this test passes.\n",
    "* Tests can check for all the different scenarios and edge cases you can think of, before even starting to write your function. This way, when you do start implementing your function, you can run this test to get immediate feedback on whether it works or not in all the ways you can think of, as you tweak your function.\n",
    "* When refactoring or adding to your code, tests help you rest assured that the rest of your code didn't break while you were making those changes. Tests also helps ensure that your function behavior is repeatable, regardless of external parameters, such as hardware and time.\n",
    "\n",
    "Test driven development for data science is relatively new and has a lot of experimentation and breakthroughs appearing, which you can learn more about in the resources below.\n",
    "\n",
    "[Data Science TDD](https://www.linkedin.com/pulse/data-science-test-driven-development-sam-savage/)\n",
    "\n",
    "[TDD for Data Science](http://engineering.pivotal.io/post/test-driven-development-for-data-science/)\n",
    "\n",
    "[TDD is Essential for Good Data Science Here's Why](https://medium.com/uk-hydrographic-office/test-driven-development-is-essential-for-good-data-science-heres-why-db7975a03a44)\n",
    "\n",
    "[Testing Your Code (general python TDD)](https://docs.python-guide.org/writing/tests/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
